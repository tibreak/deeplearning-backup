{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data sets \n",
    "url:http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Q1:如何加载数据集,显示数据集的及大小，理解编码方式(One-hot)\n",
    "Q2:如何显示图像\n",
    "Q3:如何利用keras搭建并训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "###load dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist=input_data.read_data_sets(\"./MNIST_data\",one_hot=True)\n",
    "? dir()#####dir 是一个内置函数，用于列出对象的所有属性及方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog():\n",
    "    def __init__(self,name,age):\n",
    "        self.name=name\n",
    "        self.age=age\n",
    "    \n",
    "    def sit(self):\n",
    "        print(self.name,\"is sitting on the ground\")\n",
    "        \n",
    "    def roll_over(self):\n",
    "        print(self.name,\"rolled over\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 类中的函数称为方法\n",
    "2. __init__(前后2个下划线）是一个特殊的方法，每次根据Dog类创建新的实例时，Python自动运行它。\n",
    "3. __init__有3个形参，self,name,age。python调用__init__创建Dog实例时，自动传入self.每个与类相关联的\n",
    "方法的调用都自动传递实参self.它指向实例本身，让实例访问类的属性和方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WangWang is 3 years old\n"
     ]
    }
   ],
   "source": [
    "my_dog=Dog(\"WangWang\",3)\n",
    "print(my_dog.name,\"is\",my_dog.age,\"years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WangWang is sitting on the ground\n"
     ]
    }
   ],
   "source": [
    "my_dog.sit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WangWang rolled over\n"
     ]
    }
   ],
   "source": [
    "my_dog.roll_over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'age',\n",
       " 'name',\n",
       " 'roll_over',\n",
       " 'sit']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(my_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'roll_over',\n",
       " 'sit']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_Y,test_X,test_Y=mnist.train.images,mnist.train.labels,\\\n",
    "mnist.test.images,mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10) (10000, 784) (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape,train_Y.shape,test_X.shape,test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 784和10表示什么意思？$784=28^2$。10表示10位one_hot(独热)编码方式。如1可表示为[0 1 0 0 0 0 0 0 0 0],9表为 [0 0 0 0 0 0 0 0 0 1]\n",
    "\n",
    "2. 为什么用独热编码？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b51c8f3358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "fig,axis=plt.subplots(1,10,figsize=(10,7))\n",
    "for i in range(10):\n",
    "    img=np.reshape(train_X[i,:],(28,28))\n",
    "    axis[i].imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=256)`\n",
      "  \"\"\"\n",
      "e:\\python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=256, activation=\"softmax\", units=10)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.optimizers import SGD\n",
    "model=Sequential()\n",
    "model.add(Dense(input_dim=28*28,output_dim=256,activation='relu'))\n",
    "model.add(Dense(input_dim=256,output_dim=10,activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 2s 39us/step - loss: 1.5844 - acc: 0.6094\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 2s 30us/step - loss: 0.8420 - acc: 0.8241\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 2s 30us/step - loss: 0.6247 - acc: 0.8541\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 2s 31us/step - loss: 0.5286 - acc: 0.8688\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 2s 30us/step - loss: 0.4738 - acc: 0.8781\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.4376 - acc: 0.8849\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.4116 - acc: 0.8903\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.3918 - acc: 0.8937\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.3762 - acc: 0.8969\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.3630 - acc: 0.9002\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.3520 - acc: 0.9024\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.3423 - acc: 0.9049\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.3339 - acc: 0.9064\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.3263 - acc: 0.9086\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 2s 44us/step - loss: 0.3194 - acc: 0.9105: 0s - loss: 0.\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.3131 - acc: 0.9123\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.3073 - acc: 0.9139\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.3018 - acc: 0.9152\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2967 - acc: 0.9168\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2918 - acc: 0.9183\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.2873 - acc: 0.9197\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2830 - acc: 0.9211\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2787 - acc: 0.9223\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.2748 - acc: 0.9233\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - ETA: 0s - loss: 0.2706 - acc: 0.924 - 2s 41us/step - loss: 0.2709 - acc: 0.9242\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 2s 44us/step - loss: 0.2672 - acc: 0.9255\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 3s 50us/step - loss: 0.2636 - acc: 0.9265\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.2602 - acc: 0.9277\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2569 - acc: 0.9286\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.2536 - acc: 0.9298\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2504 - acc: 0.9304\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2474 - acc: 0.9313\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2444 - acc: 0.9325\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2416 - acc: 0.9331\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2388 - acc: 0.9340\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.2361 - acc: 0.9347\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.2334 - acc: 0.9355\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2309 - acc: 0.9365\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.2283 - acc: 0.9371\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2258 - acc: 0.9379\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2234 - acc: 0.9381\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.2211 - acc: 0.9389\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.2188 - acc: 0.9394\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 2s 43us/step - loss: 0.2165 - acc: 0.9403\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.2143 - acc: 0.9408\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.2122 - acc: 0.9413\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.2101 - acc: 0.9419\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.2080 - acc: 0.9424\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.2060 - acc: 0.9430\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.2040 - acc: 0.9438\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.2020 - acc: 0.9441\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 2s 42us/step - loss: 0.2001 - acc: 0.9449\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 2s 39us/step - loss: 0.1984 - acc: 0.9451\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 3s 47us/step - loss: 0.1965 - acc: 0.9457\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 3s 46us/step - loss: 0.1947 - acc: 0.9462\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1929 - acc: 0.9468\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 2s 45us/step - loss: 0.1911 - acc: 0.9473\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 2s 39us/step - loss: 0.1895 - acc: 0.9478\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.1878 - acc: 0.9481\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1862 - acc: 0.9485\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.1845 - acc: 0.9487\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1829 - acc: 0.9494\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 2s 39us/step - loss: 0.1815 - acc: 0.9499\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.1799 - acc: 0.9504\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 3s 46us/step - loss: 0.1784 - acc: 0.9505\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 3s 53us/step - loss: 0.1769 - acc: 0.9511\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 3s 48us/step - loss: 0.1755 - acc: 0.9515\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 3s 50us/step - loss: 0.1741 - acc: 0.9520\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 2s 44us/step - loss: 0.1726 - acc: 0.9523\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 2s 44us/step - loss: 0.1713 - acc: 0.9531\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 2s 45us/step - loss: 0.1699 - acc: 0.9533\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1685 - acc: 0.9536\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.1672 - acc: 0.9538\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1659 - acc: 0.9540\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1647 - acc: 0.9547\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.1633 - acc: 0.9547\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 2s 39us/step - loss: 0.1621 - acc: 0.9548\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 3s 47us/step - loss: 0.1609 - acc: 0.9553\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1597 - acc: 0.9557\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1585 - acc: 0.9560\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1573 - acc: 0.9565\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1562 - acc: 0.9565\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 0.1550 - acc: 0.9568\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.1539 - acc: 0.9572\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 3s 50us/step - loss: 0.1528 - acc: 0.9573\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1517 - acc: 0.9581\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 2s 41us/step - loss: 0.1506 - acc: 0.9583\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1496 - acc: 0.9585\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1485 - acc: 0.9589\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1474 - acc: 0.9593\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1465 - acc: 0.9593\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 2s 37us/step - loss: 0.1454 - acc: 0.9598\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1444 - acc: 0.9603\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1435 - acc: 0.9605\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1425 - acc: 0.9608\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1415 - acc: 0.9612\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1406 - acc: 0.9614\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 2s 36us/step - loss: 0.1397 - acc: 0.9618\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1388 - acc: 0.9622\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 2s 35us/step - loss: 0.1378 - acc: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b51e84d748>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,train_Y,batch_size=256,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得程序运行时间\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "###程序段#####\n",
    "###程序段#####\n",
    "\n",
    "end_time=time.time()\n",
    "\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n",
      "test loss:0.1436 test accuracy:0.9591\n"
     ]
    }
   ],
   "source": [
    "evaluation=model.evaluate(test_X,test_Y,batch_size=256,verbose=1)\n",
    "print(\"test loss:%.4f\"%(evaluation[0]),\"test accuracy:%.4f\"%(evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 1.6137 - acc: 0.6193\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.7413 - acc: 0.8425\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.5135 - acc: 0.8746\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.4301 - acc: 0.8870\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.3860 - acc: 0.8959\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.3576 - acc: 0.9012\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 5s 91us/step - loss: 0.3370 - acc: 0.9062\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.3209 - acc: 0.9099\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.3075 - acc: 0.9130\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 6s 104us/step - loss: 0.2960 - acc: 0.9165\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 5s 96us/step - loss: 0.2858 - acc: 0.9190\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 0.2770 - acc: 0.9214\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 0.2687 - acc: 0.9235: 0s - loss: 0.2682 - ac\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 0.2612 - acc: 0.9259\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 5s 94us/step - loss: 0.2542 - acc: 0.9277\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2476 - acc: 0.9291\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2413 - acc: 0.9313\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2355 - acc: 0.9332\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.2301 - acc: 0.9347\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 0.2246 - acc: 0.9362\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.2197 - acc: 0.9380\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2149 - acc: 0.9392\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2102 - acc: 0.9404\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.2060 - acc: 0.9412\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.2018 - acc: 0.9430\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.1977 - acc: 0.9441\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.1938 - acc: 0.9451\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.1899 - acc: 0.9464\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1863 - acc: 0.9473\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1830 - acc: 0.9481\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1796 - acc: 0.9492\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1764 - acc: 0.9498\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.1733 - acc: 0.9509\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 0.1703 - acc: 0.9522\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.1674 - acc: 0.9530\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1646 - acc: 0.9539\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1617 - acc: 0.9547\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1591 - acc: 0.9555\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 0.1565 - acc: 0.9562\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 6s 117us/step - loss: 0.1540 - acc: 0.9572 0s - loss: 0.1539 - acc:\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 0.1516 - acc: 0.9577\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 5s 94us/step - loss: 0.1492 - acc: 0.9585\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 0.1470 - acc: 0.9594\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 5s 90us/step - loss: 0.1448 - acc: 0.9598\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 5s 97us/step - loss: 0.1425 - acc: 0.9607\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.1404 - acc: 0.9608\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.1384 - acc: 0.9615\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.1363 - acc: 0.9619: 0s - loss: 0.1364 - acc: 0.96\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1343 - acc: 0.9628\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1324 - acc: 0.9634: 0s - loss: 0.1331 - a\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1307 - acc: 0.9637\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1289 - acc: 0.9646: 1s -\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.1270 - acc: 0.9645\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1254 - acc: 0.9654\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1237 - acc: 0.9660\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1219 - acc: 0.9667\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1203 - acc: 0.9668\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1187 - acc: 0.9674\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1173 - acc: 0.9679\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 4s 69us/step - loss: 0.1156 - acc: 0.9679\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1142 - acc: 0.9687\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1127 - acc: 0.9688\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.1113 - acc: 0.9694\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1099 - acc: 0.9698\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.1085 - acc: 0.9701\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 0.1072 - acc: 0.9707\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.1059 - acc: 0.9711: \n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.1046 - acc: 0.9712\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.1033 - acc: 0.9716\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.1020 - acc: 0.9719\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 0.1008 - acc: 0.9725\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 0.0996 - acc: 0.9726\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 0.0983 - acc: 0.9734\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 6s 103us/step - loss: 0.0972 - acc: 0.9733\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 5s 98us/step - loss: 0.0961 - acc: 0.9739\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.0950 - acc: 0.9739\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 5s 86us/step - loss: 0.0938 - acc: 0.9744\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 5s 95us/step - loss: 0.0928 - acc: 0.9747\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0918 - acc: 0.9746\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.0907 - acc: 0.9752\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 5s 94us/step - loss: 0.0897 - acc: 0.9756\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 5s 94us/step - loss: 0.0887 - acc: 0.9758\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 5s 96us/step - loss: 0.0877 - acc: 0.9759\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 0.0867 - acc: 0.9764\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0857 - acc: 0.9765\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.0847 - acc: 0.9769\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.0838 - acc: 0.9774\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.0829 - acc: 0.9773\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0820 - acc: 0.9777\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 0.0811 - acc: 0.9782\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0802 - acc: 0.9780\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 0.0793 - acc: 0.9785\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0785 - acc: 0.9790\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 0.0777 - acc: 0.9790: 0s - loss: 0.0788\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0768 - acc: 0.9793\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.0761 - acc: 0.9797\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0752 - acc: 0.9798\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0744 - acc: 0.9799\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0736 - acc: 0.9805\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.0728 - acc: 0.9805\n",
      "451.415851354599\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "my_model.fit(train_X,train_Y,batch_size=256,epochs=100,verbose=1)\n",
    "end_time=time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning time:451.42 second(s)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainning time:%.2f\"%(end_time-start_time),'second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step\n",
      "my_model test loss:0.0946 corresponding test accuracy:0.9708\n"
     ]
    }
   ],
   "source": [
    "evaluation=my_model.evaluate(test_X,test_Y,batch_size=256,verbose=1)\n",
    "print(\"my_model test loss:%.4f\"%(evaluation[0]),\"corresponding test accuracy:%.4f\"%(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 由此可见增加网络的层数可以提高模型的准确率！如果引入许多层(>6)的网络那么准确率可以很高，但是也会出现过拟合(Overfitting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
